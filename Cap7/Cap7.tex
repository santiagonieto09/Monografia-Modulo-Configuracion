\mychapter{Capítulo 7. Evaluación de funcionalidades}

En este capítulo se describen las pruebas realizadas al módulo de configuración, con el objetivo de evaluar sus funcionalidades y verificar su correcto funcionamiento e integración con el resto del sistema.


\section{Pruebas del backend}

\subsection{Pruebas unitarias}

Las pruebas unitarias juegan un rol esencial en la ingeniería de software, ya que permiten comprobar el funcionamiento adecuado de partes específicas del código de forma aislada. En el marco de este proyecto, se implementaron pruebas unitarias utilizando JUnit 5 y Mockito, herramientas que colaboran para facilitar la generación de pruebas automáticas. JUnit 5 suministra el esqueleto para planificar, organizar y ejecutar los tests, mientras que Mockito replica el comportamiento de dependencias externas usando objetos simulados, lo que asegura un completo aislamiento de cada unidad durante su evaluación. Esta integración de tecnologías asegura que cada componente funcional satisfaga los criterios establecidos antes de integrarse con el resto del sistema. 

Para obtener pruebas ágiles y eficaces, se optó por evitar contextos pesados como Spring Boot, enfocándose en testar los fragmentos de código de manera independiente. Este método ofrece retroalimentación rápida en el proceso de desarrollo y permite identificar errores en etapas iniciales.

Los aspectos generales de cobertura incluyen:
\begin{itemize}
\item Alta cobertura en las clases de dominio, lógica de negocio, adaptadores de entrada y salida críticos
\item Los Mappers tienen una cobertura de 0\% ya que no se implentan pruebas unitarias para estas clases, dado que se usa @Mapper de MapStruct que genera código automáticamente y no se considera necesario probar estas clases directamente.
\item Otros casos como las configuraciones con @Bean también presentan una cobertura baja debido a la naturaleza declarativa de su implementación.
\end{itemize}

Como se muestra en la Figura \ref{fig:testcatalogue}, se ejecutaron un total de 1496 pruebas unitarias para el microservicio \texttt{account\_catalogue}, todas ellas completadas satisfactoriamente, lo que puede ayudar a una mayor confianza y estabilidad del código implementado.

\begin{figure}[h!]
    \centering%
    \includegraphics[width=0.7\textwidth, height=0.7\textheight, keepaspectratio]{Cap7/Figuras/testCatalogue.png}    
    \caption{Resultado ejecución pruebas unitarias microservicio \texttt{account\_catalogue}}
    \label{fig:testcatalogue}
\end{figure}
 
Para asegurar una cobertura adecuada del código, se utilizó JaCoCo (Java Code Coverage), una herramienta que permite medir y visualizar la cobertura de código alcanzada por las pruebas unitarias. Debido a que los paquetes del microservicio \texttt{account\_catalogue} son demasiados se mostraran los resultados por partes, las Figuras \ref{fig:jacocoCataloguep1}, \ref{fig:jacocoCataloguep2} y \ref{fig:jacocoCataloguep3} muestran el informe de cobertura generado por JaCoCo.

\begin{figure}[h!]
    \centering%
    \includegraphics[width=1.0\textwidth, height=1.0\textheight, keepaspectratio]{Cap7/Figuras/jacocoCataloguep1.png}    
    \caption{Resultados jacoco \texttt{account\_catalogue} parte 1}
    \label{fig:jacocoCataloguep1}
\end{figure}

\begin{figure}[h!]
    \centering%
    \includegraphics[width=1.0\textwidth, height=1.0\textheight, keepaspectratio]{Cap7/Figuras/jacocoCataloguep2.png}    
    \caption{Resultados jacoco \texttt{account\_catalogue} parte 2}
    \label{fig:jacocoCataloguep2}
\end{figure}

\begin{figure}[h!]
    \centering%
    \includegraphics[width=1.0\textwidth, height=1.0\textheight, keepaspectratio]{Cap7/Figuras/jacocoCataloguep3.png}    
    \caption{Resultados jacoco \texttt{account\_catalogue} parte 3}
    \label{fig:jacocoCataloguep3}
\end{figure}

\newpage
El informe de JaCoCo revela una cobertura general del 57\% del código, lo que representa un nivel inferior, esta cobertura reducida se explica principalmente por el hecho de que el microservicio \texttt{account\_catalogue} es compartido entre el módulo de cartera y el módulo contable cartera, lo que implica que las funcionalidades y clases del módulo de contabilidad no se cubrieron en las pruebas unitarias, ya que dichos módulos están en construcción y no han alcanzado su fase de pruebas hasta el momento.


Como se muestra en la Figura \ref{fig:testconfiguracion}, se ejecutaron un total de 603 pruebas unitarias para el microservicio \texttt{ms-configuration}, todas ellas completadas satisfactoriamente.

\begin{figure}[h!]
    \centering%
    \includegraphics[width=0.7\textwidth, height=0.7\textheight, keepaspectratio]{Cap7/Figuras/testConfiguracion.png}    
    \caption{Resultado de ejecución pruebas unitarias \texttt{ms-configuration} }
    \label{fig:testconfiguracion}
\end{figure}

\newpage
Las Figuras \ref{fig:jacocoConfiguracion1} y \ref{fig:jacocoConfiguracion2} muestran el informe de cobertura generado por JaCoCo.


\begin{figure}[h!]
    \centering%
    \includegraphics[width=1.0\textwidth, height=1.0\textheight, keepaspectratio]{Cap7/Figuras/jacocoConfig1.png}    
    \caption{Resultados jacoco \texttt{ms-configuration} parte 1}
    \label{fig:jacocoConfiguracion1} 
\end{figure}

\begin{figure}[h!]
    \centering%
    \includegraphics[width=1.0\textwidth, height=1.0\textheight, keepaspectratio]{Cap7/Figuras/jacocoConfig2.png}    
    \caption{Resultados jacoco \texttt{ms-configuration} parte 2}
    \label{fig:jacocoConfiguracion2} 
\end{figure}

\newpage
El informe de JaCoCo revela una cobertura general del 77\% del código, con algunas clases alcanzando el 100\% de cobertura. Este nivel de cobertura se considera aceptable para el proyecto, aunque se identifican áreas de oportunidad para mejorar
la cobertura en algunas clases específicas.


Como se muestra en la Figura \ref{fig:testproductos}, se ejecutaron un total de 776 pruebas unitarias para el microservicio \texttt{products-management}, todas ellas completadas satisfactoriamente.

\begin{figure}[h!]
    \centering%
    \includegraphics[width=0.7\textwidth, height=0.7\textheight, keepaspectratio]{Cap7/Figuras/testProductos.png}    
    \caption{Resultado de ejecución pruebas unitarias \texttt{ms-productos} }
    \label{fig:testproductos} 
\end{figure}

La Figura \ref{fig:jacocoProductos} muestra el informe de cobertura generado por JaCoCo.

\begin{figure}[h!]
    \centering%
    \includegraphics[width=1.0\textwidth, height=1.0\textheight, keepaspectratio]{Cap7/Figuras/jacocoProductos.png}    
    \caption{Resultado jacoco microservicio \texttt{ms-productos} }
    \label{fig:jacocoProductos} 
\end{figure}

\newpage
El informe de JaCoCo revela una cobertura general del 81\% del código, con algunas clases alcanzando el 100\% de cobertura. Este nivel de cobertura se considera aceptable para el proyecto, aunque se identifican áreas de oportunidad para mejorar la cobertura en algunas clases específicas.


Como se muestra en la Figura \ref{fig:testterceros}, se ejecutaron un total de 1720 pruebas unitarias para el microservicio \texttt{thirds-management}, todas ellas completadas satisfactoriamente.

\begin{figure}[h!]
    \centering%
    \includegraphics[width=0.7\textwidth, height=0.7\textheight, keepaspectratio]{Cap7/Figuras/testTerceros.png}    
    \caption{Resultado de ejecución pruebas unitarias \texttt{ms-terceros} }
    \label{fig:testterceros} 
\end{figure}

La Figura \ref{fig:jacocoTerceros} muestra el informe de cobertura generado por JaCoCo.

\begin{figure}[h!]
    \centering%
    \includegraphics[width=1.0\textwidth, height=1.0\textheight, keepaspectratio]{Cap7/Figuras/jacocoTerceros.png}    
    \caption{Resultado jacoco microservicio \texttt{ms-terceros} }
    \label{fig:jacocoTerceros} 
\end{figure}


El informe de JaCoCo revela una cobertura general del 83\% del código, con algunas clases alcanzando el 100\% de cobertura. Este nivel de cobertura se considera aceptable para el proyecto, aunque se identifican áreas de oportunidad para mejorar la cobertura en algunas clases específicas.


\subsection{Pruebas de integración}

Las pruebas de integración representan un elemento esencial para comprobar que los diversos componentes del sistema operen de forma adecuada en conjunto. En el marco de este proyecto, resultaba indispensable asegurar que el módulo de configuración no únicamente operara correctamente en aislamiento, sino que además interactuara de manera perfecta y segura con los demás elementos del entorno de microservicios. Una integración apropiada es vital para mantener la coherencia y la integridad de la información a lo largo de toda la aplicación, particularmente en un sistema distribuido que emplea eventos para la comunicación.

\subsection{Estrategia de pruebas de integración}

Para lograr este objetivo se diseñó una estrategia de pruebas de integración de caja negra que simula el comportamiento real del sistema. Dado que el módulo de configuración opera de forma mayoritariamente síncrona, respondiendo a solicitudes HTTP directas a través de endpoints REST, la estrategia se enfoca en validar el flujo completo de manera directa. La estrategia implementada valida el flujo completo mediante un proceso de dos etapas:

\begin{enumerate}
\item \textbf{Invocación del endpoint}: Se realiza una llamada HTTP directa al endpoint REST correspondiente. Esta solicitud simula una operación real del sistema, como la creación o consulta de un recurso, permitiendo probar el punto de entrada principal del módulo. Esta etapa valida la capacidad del sistema para procesar y validar correctamente las solicitudes entrantes.

\item \textbf{Verificación del resultado}: Dado que el procesamiento es síncrono, se verifica inmediatamente la respuesta del endpoint y se consulta la base de datos para confirmar el estado actualizado. Esto permite confirmar si la lógica de negocio se ejecutó correctamente y si el estado del sistema se actualizó como se esperaba, validando tanto la persistencia en la base de datos como la correcta exposición de los resultados a través de la API.
\end{enumerate}

Este enfoque valida la integración completa del módulo de configuración con tres componentes críticos de la arquitectura:

\begin{itemize}
\item API REST: Se demuestra que el módulo procesa y responde a las solicitudes correctamente.
\item Base de datos: Se confirma que tras procesar una solicitud, el estado se persiste de forma correcta.
\item Lógica de validación: Se asegura que las y validaciones se ejecutan de manera correcta.
\end{itemize}

Esta cobertura proporciona una alta confianza en que el módulo no solo realiza sus operaciones de forma correcta, sino que está correctamente integrado en el flujo de trabajo general de la aplicación.


\subsection{Implementación con Postman y Newman}

Se empleó Postman para diseñar las pruebas de integración y Newman para su ejecución automática. El conjunto de pruebas aplica la estrategia previamente detallada, abarcando casos positivos y negativos. La recopilación de pruebas se organizó de manera estructurada, como se muestra en la Figura \ref{fig:postman}, donde se distinguen dos estructuras principales: la fase de obtención de Token, Init, Integration y Tear Down.

Para los módulos de tipos de documentos, calendario contable, catálogo de cuentas, centros de costo y centro de ayuda, no se requería la fase Init, puesto que estos módulos no necesitan una inicialización previa de datos para su funcionamiento.

Por otro lado, el módulo de cuentas bancarias necesita datos iniciales de cuentas contables auxiliares, al igual que impuestos y métodos de pago. El módulo de productos requiere inicialmente un tipo de producto, categoría y unidad de medida. Finalmente, el módulo de terceros necesita datos como tipos de identificación y tipos de terceros para la correcta ejecución de las pruebas.

\begin{figure}[h!]
    \centering%
    \includegraphics[width=0.5\textwidth, height=0.5\textheight, keepaspectratio]{Cap7/Figuras/postman.png}    
    \caption{Estructura de la colección de pruebas en Postman}
    \label{fig:postman} 
\end{figure}

\subsection{Casos de prueba: Escenarios positivos y negativos}

La implementación de pruebas se divide en dos categorías fundamentales que validan la robustez del sistema:

\textbf{Pruebas de caso positivo (Happy Path)}: Estas pruebas validan que, ante una solicitud válida (como crear un tipo de documento con todos sus datos correctos), el sistema procesa la solicitud, actualiza la base de datos correctamente. El flujo de validación consiste en: (1) enviar una solicitud HTTP válida al endpoint correspondiente, (2) verificar la respuesta inmediata, y (3) consultar la base de datos para confirmar que el estado refleja correctamente la operación realizada. Esto asegura que la funcionalidad principal opera según lo diseñado y que la integración entre componentes es exitosa.

\textbf{Pruebas de caso negativo (Sad Path)}: Igualmente importante fue verificar que el sistema maneja los errores de forma robusta y observable. Para ello se envían solicitudes con datos inválidos, como crear un tipo de documento sin nombre o con valores incorrectos. En estos casos, se verifica la respuesta de error. La prueba es exitosa si confirma que el error fue capturado, registrado y expuesto correctamente a través de la API. Esto garantiza que el sistema es resiliente y no falla de manera silenciosa, cumpliendo con el principio de observabilidad necesario en arquitecturas de microservicios.

Para validar los resultados de manera automática, se implementaron scripts post-respuesta en Postman, como se muestra en la Figura \ref{fig:postmanscripts}. Estos scripts permiten ejecutar verificaciones automáticas sobre las respuestas recibidas, validando tanto la estructura de los datos como los valores esperados en cada escenario.

\begin{figure}[h!]
    \centering%
    \includegraphics[width=1.0\textwidth, height=1.0\textheight, keepaspectratio]{Cap7/Figuras/postmanscripts.png}    
    \caption{Implementación de scripts post-respuesta en Postman}
    \label{fig:postmanscripts} 
\end{figure}

Los scripts verifican múltiples aspectos de las respuestas:
\begin{itemize}
\item Validación del código de estado HTTP (200 para casos exitosos, códigos de error apropiados para casos negativos)
\item Verificación de la estructura correcta de la respuesta JSON
\item Validación del contenido contra el payload esperado
\item Comprobación de campos obligatorios y sus tipos de datos
\item En casos negativos, validación de la presencia y formato de mensajes de error
\end{itemize}



\subsection{Ejecución automatizada con Newman}

